import cv2
import numpy as np
import time
import warnings

warnings.filterwarnings('ignore')
from ultralytics import YOLO

# ========== é…ç½®å‚æ•° ==========
MODEL_PATH = 'Yolo/best-obb-225.pt'  # æ¨¡å‹æ–‡ä»¶è·¯å¾„
CAMERA_INDEX = 0                # æ‘„åƒå¤´ç´¢å¼•
CONF_THRESHOLD = 0.3            # ç½®ä¿¡åº¦é˜ˆå€¼
INPUT_SIZE = 640               # è¾“å…¥å›¾åƒå°ºå¯¸

# ========== åœ†åœˆæ£€æµ‹é…ç½® ==========
CIRCLE_CENTER_X = 355           # åœ†åœˆä¸­å¿ƒXåæ ‡
CIRCLE_CENTER_Y = 200           # åœ†åœˆä¸­å¿ƒYåæ ‡  
CIRCLE_RADIUS = 110             # åœ†åœˆåŠå¾„
CIRCLE_COLOR = (120, 205, 0)      # åœ†åœˆé¢œè‰²ï¼ˆç»¿è‰²ï¼‰
CIRCLE_THICKNESS = 2            # åœ†åœˆçº¿æ¡ç²—ç»†

def list_available_cameras():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ‘„åƒå¤´"""
    available_cameras = []
    print("ğŸ” æ‰«æå¯ç”¨æ‘„åƒå¤´...")
    
    for i in range(10):  # æ£€æŸ¥å‰10ä¸ªæ‘„åƒå¤´ç´¢å¼•
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret and frame is not None:
                # è·å–æ‘„åƒå¤´ä¿¡æ¯
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                
                camera_info = {
                    'index': i,
                    'width': width,
                    'height': height,
                    'fps': fps
                }
                available_cameras.append(camera_info)
                print(f"ğŸ“· æ‘„åƒå¤´ {i}: {width}x{height} @ {fps}FPS")
            cap.release()
    
    if not available_cameras:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨æ‘„åƒå¤´")
    
    return available_cameras

# ========== å…¨å±€å˜é‡ ==========
model = None
cap = None
target_status = {}              # è·Ÿè¸ªæ¯ä¸ªç›®æ ‡æ˜¯å¦åœ¨åœ†åœˆå†…çš„çŠ¶æ€

def initialize_model():
    """åˆå§‹åŒ–YOLOæ¨¡å‹"""
    global model
    try:
        print("ğŸ”§ æ­£åœ¨åŠ è½½YOLOæ¨¡å‹...")
        model = YOLO(MODEL_PATH)
        
        # æ£€æµ‹å¯ç”¨è®¾å¤‡
        try:
            import torch
            if torch.cuda.is_available():
                device = 'cuda'
                print("âœ… æ£€æµ‹åˆ°CUDAæ”¯æŒï¼Œä½¿ç”¨GPU")
            else:
                device = 'cpu'
                print("âš ï¸ æœªæ£€æµ‹åˆ°CUDAæ”¯æŒï¼Œä½¿ç”¨CPU")
        except:
            device = 'cpu'
            print("âš ï¸ æ— æ³•æ£€æµ‹è®¾å¤‡ï¼Œä½¿ç”¨CPU")
        
        # æ¨¡å‹ä¼˜åŒ–è®¾ç½®
        model.overrides.update({
            'verbose': False,      # å…³é—­è¯¦ç»†è¾“å‡º
            'device': device,      # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
            'half': False,        # ä¸ä½¿ç”¨åŠç²¾åº¦
            'agnostic_nms': True, # ç±»åˆ«æ— å…³çš„éæå¤§å€¼æŠ‘åˆ¶
            'max_det': 50,        # æœ€å¤§æ£€æµ‹æ•°é‡
        })
        
        print("âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def initialize_camera():
    """åˆå§‹åŒ–æ‘„åƒå¤´"""
    global cap
    
    print("ğŸ¥ æ­£åœ¨åˆå§‹åŒ–æ‘„åƒå¤´...")
    
    # ç›´æ¥ä½¿ç”¨1å·æ‘„åƒå¤´
    camera_index = 1
    print(f"ğŸ“· æ­£åœ¨åˆå§‹åŒ–æ‘„åƒå¤´ {camera_index}...")
    
    # å°è¯•ä¸åŒçš„åç«¯
    backends = [cv2.CAP_DSHOW, cv2.CAP_ANY]
    
    for backend in backends:
        cap = cv2.VideoCapture(camera_index, backend)
        if cap.isOpened():
            # è®¾ç½®æ‘„åƒå¤´å±æ€§
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # å‡å°‘ç¼“å†²å»¶è¿Ÿ
            
            ret, frame = cap.read()
            if ret and frame is not None:
                actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                actual_fps = int(cap.get(cv2.CAP_PROP_FPS))
                
                print(f"âœ… æ‘„åƒå¤´ {camera_index} åˆå§‹åŒ–æˆåŠŸï¼")
                print(f"   åˆ†è¾¨ç‡: {actual_width}x{actual_height}")
                print(f"   å¸§ç‡: {actual_fps}FPS")
                print(f"   åç«¯: {'DirectShow' if backend == cv2.CAP_DSHOW else 'Default'}")
                return True
            else:
                cap.release()
        
    print(f"âŒ æ‘„åƒå¤´ {camera_index} åˆå§‹åŒ–å¤±è´¥ï¼")
    return False

def detect_objects(frame):
    """ç›®æ ‡æ£€æµ‹å‡½æ•°"""
    global model
    
    if model is None:
        return []
    
    try:
        # æ£€æµ‹å¯ç”¨è®¾å¤‡
        try:
            import torch
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        except:
            device = 'cpu'
        
        # æ‰§è¡ŒYOLOæ£€æµ‹
        results = model.predict(
            source=frame,
            imgsz=INPUT_SIZE,
            conf=CONF_THRESHOLD,
            verbose=False,
            device=device  # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        )
        
        detections = []
        
        # è§£ææ£€æµ‹ç»“æœ
        for r in results:
            if r.obb is not None and len(r.obb.data) > 0:
                for detection in r.obb.data:
                    try:
                        # è·å–æ£€æµ‹æ•°æ®
                        det_data = detection.cpu().numpy()
                        center_x = float(det_data[0])
                        center_y = float(det_data[1])
                        width = float(det_data[2])
                        height = float(det_data[3])
                        angle = float(det_data[4])
                        confidence = float(det_data[5])
                        class_id = int(det_data[6])
                        
                        # IDæ˜ å°„ï¼ˆæ ¹æ®åŸä»£ç çš„æ˜ å°„è§„åˆ™ï¼‰
                        output_id = str(class_id)
                        if class_id == 3:
                            output_id = "0"
                        elif class_id == 0:
                            output_id = "3"
                        
                        detection_result = {
                            "id": output_id,
                            "center_x": center_x,
                            "center_y": center_y,
                            "width": width,
                            "height": height,
                            "angle": angle,
                            "confidence": confidence,
                            "class_id": class_id
                        }
                        
                        detections.append(detection_result)
                        
                    except Exception as e:
                        print(f"æ£€æµ‹æ•°æ®è§£æé”™è¯¯: {e}")
                        continue
        
        return detections
        
    except Exception as e:
        print(f"âŒ æ£€æµ‹é”™è¯¯: {e}")
        return []

def draw_detections(frame, detections):
    """åœ¨ç”»é¢ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    
    # ç»˜åˆ¶å¤§åœ†åœˆ
    cv2.circle(frame, (CIRCLE_CENTER_X, CIRCLE_CENTER_Y), CIRCLE_RADIUS, CIRCLE_COLOR, CIRCLE_THICKNESS)
    
    # åœ¨åœ†åœˆä¸­å¿ƒç»˜åˆ¶ä¸€ä¸ªå°ç‚¹ä½œä¸ºå‚è€ƒ
    cv2.circle(frame, (CIRCLE_CENTER_X, CIRCLE_CENTER_Y), 3, CIRCLE_COLOR, -1)
    
    for det in detections:
        # åªæ˜¾ç¤ºIDä¸º0ã€1ã€2ã€3çš„æ£€æµ‹ç»“æœ
        object_id = det['id']
        if object_id not in ['0', '1', '2', '3']:
            continue  # è·³è¿‡å…¶ä»–ID
            
        center_x = int(det['center_x'])
        center_y = int(det['center_y'])
        width = det['width']
        height = det['height']
        angle = det['angle']
        confidence = det['confidence']
        
        # æ£€æŸ¥ç›®æ ‡æ˜¯å¦ç¦»å¼€åœ†åœˆ
        check_circle_exit(object_id, center_x, center_y)
        
        # æ ¹æ®ç›®æ ‡æ˜¯å¦åœ¨åœ†åœˆå†…é€‰æ‹©é¢œè‰²
        in_circle = is_target_in_circle(center_x, center_y)
        center_color = (0, 255, 0) if in_circle else (0, 0, 255)  # ç»¿è‰²ï¼šåœ†åœˆå†…ï¼Œçº¢è‰²ï¼šåœ†åœˆå¤–
        box_color = (255, 0, 0) if in_circle else (0, 0, 255)     # è“è‰²ï¼šåœ†åœˆå†…ï¼Œçº¢è‰²ï¼šåœ†åœˆå¤–
        
        # ç»˜åˆ¶ä¸­å¿ƒç‚¹
        cv2.circle(frame, (center_x, center_y), 2, center_color, -1)
        
        # ç»˜åˆ¶æ—‹è½¬çŸ©å½¢æ¡†
        try:
            # è®¡ç®—çŸ©å½¢çš„å››ä¸ªè§’ç‚¹
            cos_a = np.cos(np.radians(angle))
            sin_a = np.sin(np.radians(angle))
            
            # çŸ©å½¢çš„åŠå®½å’ŒåŠé«˜
            w_half = width / 2
            h_half = height / 2
            
            # è®¡ç®—å››ä¸ªè§’ç‚¹
            corners = np.array([
                [-w_half, -h_half],
                [w_half, -h_half],
                [w_half, h_half],
                [-w_half, h_half]
            ])
            
            # æ—‹è½¬å˜æ¢
            rotation_matrix = np.array([
                [cos_a, -sin_a],
                [sin_a, cos_a]
            ])
            
            rotated_corners = corners @ rotation_matrix.T
            rotated_corners[:, 0] += center_x
            rotated_corners[:, 1] += center_y
            
            # ç»˜åˆ¶çŸ©å½¢
            points = rotated_corners.astype(int)
            cv2.polylines(frame, [points], True, box_color, 1)  # è°ƒç»†çº¿æ¡ç²—ç»†
            
        except Exception as e:
            # å¦‚æœæ—‹è½¬çŸ©å½¢ç»˜åˆ¶å¤±è´¥ï¼Œç»˜åˆ¶æ™®é€šçŸ©å½¢
            x1 = int(center_x - width/2)
            y1 = int(center_y - height/2)
            x2 = int(center_x + width/2)
            y2 = int(center_y + height/2)
            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 1)
        
        # æ–‡å­—æ ‡ç­¾è®¾ç½®
        font = cv2.FONT_HERSHEY_DUPLEX  # ä½¿ç”¨æ›´æ¸…æ™°çš„å­—ä½“
        font_scale = 0.35  # å‡å°å­—ä½“å°ºå¯¸
        thickness = 1     # æœ€å°å­—ä½“ç²—ç»†
        
        # åªæ˜¾ç¤ºIDæ ‡ç­¾
        label = f"ID:{object_id}"
        
        # è®¡ç®—æ–‡æœ¬ä½ç½®
        text_x = center_x + 10
        text_y = center_y - 10
        
        # ç›´æ¥ç»˜åˆ¶é»„è‰²æ–‡æœ¬ï¼ˆæ— èƒŒæ™¯ï¼‰- ä½¿ç”¨æ›´ç»†çš„çº¿æ¡
        cv2.putText(frame, label, (text_x, text_y), font, font_scale, (0, 255, 255), 1, cv2.LINE_AA)

def is_target_in_circle(center_x, center_y):
    """æ£€æŸ¥ç›®æ ‡æ˜¯å¦åœ¨åœ†åœˆå†…"""
    distance = np.sqrt((center_x - CIRCLE_CENTER_X)**2 + (center_y - CIRCLE_CENTER_Y)**2)
    return distance <= CIRCLE_RADIUS

def check_circle_exit(object_id, center_x, center_y):
    """æ£€æŸ¥ç›®æ ‡æ˜¯å¦ç¦»å¼€åœ†åœˆå¹¶æ‰“å°è­¦å‘Š"""
    global target_status
    
    current_in_circle = is_target_in_circle(center_x, center_y)
    
    # å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ°è¿™ä¸ªç›®æ ‡ï¼Œè®°å½•å…¶çŠ¶æ€
    if object_id not in target_status:
        target_status[object_id] = current_in_circle
        return
    
    # æ£€æŸ¥çŠ¶æ€æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆä»åœ†åœˆå†…ç§»åŠ¨åˆ°åœ†åœˆå¤–ï¼‰
    previous_in_circle = target_status[object_id]
    
    if previous_in_circle and not current_in_circle:
        print(f"âš ï¸  è­¦å‘Š: ID:{object_id} ç¦»å¼€äº†åœ†åœˆï¼")
    
    # æ›´æ–°çŠ¶æ€
    target_status[object_id] = current_in_circle

def main():
    """ä¸»å‡½æ•°"""
    global cap
    
    print("ğŸš€ å¯åŠ¨YOLOç›®æ ‡æ£€æµ‹ç³»ç»Ÿ...")
    
    # åˆå§‹åŒ–æ¨¡å‹
    if not initialize_model():
        print("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # åˆå§‹åŒ–æ‘„åƒå¤´
    if not initialize_camera():
        print("âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # åˆ›å»ºæ˜¾ç¤ºçª—å£
    cv2.namedWindow("YOLO Detection", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("YOLO Detection", 1000, 750)
    
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    print("ğŸ“º å¼€å§‹å®æ—¶æ£€æµ‹...")
    print("ğŸ’¡ æŒ‰ 'q' é”®é€€å‡ºç¨‹åº")
    
    # æ€§èƒ½ç»Ÿè®¡å˜é‡
    frame_count = 0
    fps_start_time = time.time()
    fps = 0
    
    try:
        while True:
            # è¯»å–æ‘„åƒå¤´å¸§
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´æ•°æ®")
                break
            
            frame_count += 1
            current_time = time.time()
            
            # è®¡ç®—FPS
            if frame_count % 30 == 0:
                fps = 30 / (current_time - fps_start_time)
                fps_start_time = current_time
            
            # æ‰§è¡Œç›®æ ‡æ£€æµ‹
            start_time = time.time()
            detections = detect_objects(frame)
            detection_time = time.time() - start_time
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            draw_detections(frame, detections)
            
            # æ€§èƒ½ä¿¡æ¯æ˜¾ç¤ºè®¾ç½®
            info_font = cv2.FONT_HERSHEY_SIMPLEX  # ä½¿ç”¨æ›´ç»†çš„å­—ä½“
            info_font_scale = 0.5  # å‡å°å­—ä½“å¤§å°
            info_thickness = 1  # æœ€å°å­—ä½“ç²—ç»†
            
            # æ€§èƒ½ä¿¡æ¯åˆ—è¡¨
            info_texts = [
                f"FPS: {fps:.1f}",
                f"Detection Time: {detection_time*1000:.1f}ms", 
                f"Objects: {len(detections)}",
                "Press 'q' to quit"
            ]
            
            # æ–‡å­—é¢œè‰²åˆ—è¡¨
            info_colors = [
                (0, 255, 0),      # ç»¿è‰² - FPS
                (0, 100, 255),    # æ©™è‰² - æ£€æµ‹æ—¶é—´
                (0, 255, 255),    # é»„è‰² - å¯¹è±¡æ•°é‡
                (255, 255, 255)   # ç™½è‰² - é€€å‡ºæç¤º
            ]
            
            # ç»˜åˆ¶æ€§èƒ½ä¿¡æ¯ï¼ˆæ— èƒŒæ™¯ï¼‰
            for i, (text, color) in enumerate(zip(info_texts, info_colors)):
                # è®¡ç®—æ–‡æœ¬ä½ç½®
                text_x = 10
                text_y = 25 + i * 25  # å‡å°è¡Œé—´è·
                
                # ç›´æ¥ç»˜åˆ¶æ–‡æœ¬ï¼ˆæ— èƒŒæ™¯ï¼‰- ä½¿ç”¨æŠ—é”¯é½¿è®©æ–‡å­—æ›´ç»†è…»
                cv2.putText(frame, text, (text_x, text_y), 
                           info_font, info_font_scale, color, 1, cv2.LINE_AA)
            
            # æ˜¾ç¤ºå›¾åƒ
            cv2.imshow("YOLO Detection", frame)
            
            # æ£€æŸ¥é€€å‡ºé”®
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("ğŸ›‘ ç”¨æˆ·é€€å‡ºç¨‹åº")
                break
                
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºè¢«ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
    finally:
        # æ¸…ç†èµ„æº
        if cap is not None:
            cap.release()
        cv2.destroyAllWindows()
        print("ğŸ”š ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main()
